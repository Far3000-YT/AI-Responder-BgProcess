# Do not change the variable names or it will break the system ! You can only change the values and strings if needed

# configure to the desired Gemini model.
# Using preview models like gemini-2.5-flash-preview-04-17 is possible,
# but be aware they may be less stable or have shorter lifespans than stable models.
# Stable models like gemini-1.5-flash-latest are generally recommended for production use.
model_name: "gemini-2.5-flash-preview-04-17"

# base prompt you need to configure depending on subject, change it and try for best results, when you are satisfied keep it
# Since short_response is removed, your base_prompt should now include instructions on
# how you want the output formatted (e.g., "Give only the final calculation result:",
# "Extract only the code block:", etc.).
base_prompt: "Analyze the following and provide only the answer or the result. Do not include explanations or conversational text."

# short_response and promptf have been removed.
# Configure your base_prompt to get the desired output format directly from the model.

# Generation parameters
max_output_tokens: 8192
top_k: 40
temperature: 0.7 # Higher than 1 = more creative, less = more factual
top_p: 0.95

# True will make this use 2 api keys and alternate between them for each request
# (API_KEY_GEMINI & API_KEY_GEMINI2 from .env).
# This can help mitigate per-minute rate limits.
# Enter "API_KEY_GEMINI" AND "API_KEY_GEMINI2" in your .env file if you enable this.
double_requests: False

# Define the command you want for a screenshot (then u select 2 points with the command of ur choice)
screenshot_cmd: 'shift+alt+รง'
point_select: 'ctrl' # This key is used AFTER the screenshot_cmd, press it twice to define the region

# Ctrl+c command will instantly ask gemini the question from clipboard text and give you the response (better if on)
ctrl_c: True

# Cooldown in seconds between initiating new requests
cooldown_seconds: 5